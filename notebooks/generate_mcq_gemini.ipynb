{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdc2bda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ google-generativeai already installed\n",
      "‚úÖ All imports successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10528\\3385970947.py:12: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Install google-generativeai n·∫øu ch∆∞a c√≥\n",
    "try:\n",
    "    import google.generativeai as genai\n",
    "    print(\"‚úÖ google-generativeai already installed\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing google-generativeai...\")\n",
    "    !pip install -q google-generativeai\n",
    "    import google.generativeai as genai\n",
    "    print(\"‚úÖ google-generativeai installed successfully\")\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5097f8e",
   "metadata": {},
   "source": [
    "## 1. Setup Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796c654b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key loaded: AIzaSyDW89nGoA7PydGC...\n",
      "‚úÖ Using model: gemini-2.5-flash (Latest & Fastest)\n",
      "‚úÖ Gemini API configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load API key t·ª´ .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Get API key\n",
    "GEMINI_KEY = os.getenv('GEMINI_KEY')\n",
    "\n",
    "if not GEMINI_KEY:\n",
    "    print(\"‚ùå GEMINI_KEY not found in .env file!\")\n",
    "    print(\"Please add: GEMINI_KEY = your_key_here\")\n",
    "else:\n",
    "    print(f\"‚úÖ API Key loaded: {GEMINI_KEY[:20]}...\")\n",
    "    \n",
    "    # Configure Gemini\n",
    "    genai.configure(api_key=GEMINI_KEY)\n",
    "    \n",
    "    # Initialize model - s·ª≠ d·ª•ng Gemini 2.5 Flash (model m·ªõi nh·∫•t)\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "        print(\"‚úÖ Using model: gemini-2.5-flash (Latest & Fastest)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  gemini-2.5-flash failed: {e}\")\n",
    "        try:\n",
    "            model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
    "            print(\"‚úÖ Using fallback: gemini-1.5-flash-latest\")\n",
    "        except:\n",
    "            model = genai.GenerativeModel('gemini-pro')\n",
    "            print(\"‚úÖ Using fallback: gemini-pro\")\n",
    "    \n",
    "    print(\"‚úÖ Gemini API configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b959b4",
   "metadata": {},
   "source": [
    "## 2. ƒê·ªãnh nghƒ©a m√¥n h·ªçc v√† prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44394bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö M√¥n h·ªçc c·∫ßn sinh c√¢u h·ªèi:\n",
      "  Priority 1: GDQP-AN - Gi√°o d·ª•c Qu·ªëc ph√≤ng - An ninh\n",
      "  Priority 1: GDTC - Gi√°o d·ª•c Th·ªÉ ch·∫•t\n",
      "  Priority 2: InformationTechnology - Tin h·ªçc\n",
      "  Priority 2: Technology - C√¥ng ngh·ªá\n",
      "  Priority 2: GDKT-PL - Gi√°o d·ª•c Kinh t·∫ø & Ph√°p lu·∫≠t\n",
      "  Priority 3: Music - √Çm nh·∫°c\n",
      "  Priority 3: Arts - M·ªπ thu·∫≠t\n"
     ]
    }
   ],
   "source": [
    "# Danh s√°ch m√¥n h·ªçc c·∫ßn sinh c√¢u h·ªèi\n",
    "SUBJECTS = {\n",
    "    # Priority 1 - B·∫Øt bu·ªôc\n",
    "    \"GDQP-AN\": {\n",
    "        \"name\": \"Gi√°o d·ª•c Qu·ªëc ph√≤ng - An ninh\",\n",
    "        \"description\": \"Gi√°o d·ª•c qu·ªëc ph√≤ng, an ninh, l·ªãch s·ª≠ qu√¢n s·ª±, chi·∫øn l∆∞·ª£c ph√≤ng th·ªß, lu·∫≠t qu√¢n s·ª±\",\n",
    "        \"priority\": 1,\n",
    "        \"questions_per_batch\": 5  # Gi·∫£m xu·ªëng 5 ƒë·ªÉ tr√°nh JSON parse errors\n",
    "    },\n",
    "    \"GDTC\": {\n",
    "        \"name\": \"Gi√°o d·ª•c Th·ªÉ ch·∫•t\",\n",
    "        \"description\": \"Th·ªÉ d·ª•c th·ªÉ thao, sinh l√Ω v·∫≠n ƒë·ªông, dinh d∆∞·ª°ng th·ªÉ thao, k·ªπ thu·∫≠t m√¥n th·ªÉ thao\",\n",
    "        \"priority\": 1,\n",
    "        \"questions_per_batch\": 5\n",
    "    },\n",
    "    \n",
    "    # Priority 2\n",
    "    \"InformationTechnology\": {\n",
    "        \"name\": \"Tin h·ªçc\",\n",
    "        \"description\": \"L·∫≠p tr√¨nh, thu·∫≠t to√°n, c∆° s·ªü d·ªØ li·ªáu, m·∫°ng m√°y t√≠nh, an ninh th√¥ng tin, c√¥ng ngh·ªá th√¥ng tin\",\n",
    "        \"priority\": 2,\n",
    "        \"questions_per_batch\": 5\n",
    "    },\n",
    "    \"Technology\": {\n",
    "        \"name\": \"C√¥ng ngh·ªá\",\n",
    "        \"description\": \"K·ªπ thu·∫≠t c√¥ng ngh·ªá, c∆° kh√≠, ƒëi·ªán t·ª≠, t·ª± ƒë·ªông h√≥a, robot, c√¥ng ngh·ªá ch·∫ø t·∫°o\",\n",
    "        \"priority\": 2,\n",
    "        \"questions_per_batch\": 5\n",
    "    },\n",
    "    \"GDKT-PL\": {\n",
    "        \"name\": \"Gi√°o d·ª•c Kinh t·∫ø & Ph√°p lu·∫≠t\",\n",
    "        \"description\": \"Kinh t·∫ø th·ªã tr∆∞·ªùng, lu·∫≠t ph√°p Vi·ªát Nam, quy·ªÅn v√† nghƒ©a v·ª• c√¥ng d√¢n, h·ª£p ƒë·ªìng, t√†i ch√≠nh c√° nh√¢n\",\n",
    "        \"priority\": 2,\n",
    "        \"questions_per_batch\": 5\n",
    "    },\n",
    "    \n",
    "    # Priority 3\n",
    "    \"Music\": {\n",
    "        \"name\": \"√Çm nh·∫°c\",\n",
    "        \"description\": \"L√Ω thuy·∫øt √¢m nh·∫°c, nh·∫°c c·ª•, th·ªÉ lo·∫°i √¢m nh·∫°c, nh√† so·∫°n nh·∫°c n·ªïi ti·∫øng, ca kh√∫c Vi·ªát Nam\",\n",
    "        \"priority\": 3,\n",
    "        \"questions_per_batch\": 5\n",
    "    },\n",
    "    \"Arts\": {\n",
    "        \"name\": \"M·ªπ thu·∫≠t\",\n",
    "        \"description\": \"H·ªôi h·ªça, ƒëi√™u kh·∫Øc, ki·∫øn tr√∫c, ngh·ªá thu·∫≠t trang tr√≠, h·ªça sƒ© n·ªïi ti·∫øng, tr∆∞·ªùng ph√°i ngh·ªá thu·∫≠t\",\n",
    "        \"priority\": 3,\n",
    "        \"questions_per_batch\": 5\n",
    "    }\n",
    "}\n",
    "\n",
    "# S·ªë c√¢u h·ªèi c·∫ßn sinh cho m·ªói m√¥n\n",
    "QUESTIONS_PER_SUBJECT = 200\n",
    "\n",
    "print(\"üìö M√¥n h·ªçc c·∫ßn sinh c√¢u h·ªèi:\")\n",
    "for subject_id, info in SUBJECTS.items():\n",
    "    print(f\"  Priority {info['priority']}: {subject_id} - {info['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c349fb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Example prompt:\n",
      "================================================================================\n",
      "B·∫°n l√† chuy√™n gia gi√°o d·ª•c THPT Vi·ªát Nam. H√£y t·∫°o 3 c√¢u h·ªèi tr·∫Øc nghi·ªám v·ªÅ m√¥n GDTC.\n",
      "\n",
      "üìö N·ªòI DUNG: Th·ªÉ d·ª•c th·ªÉ thao\n",
      "\n",
      "‚ö†Ô∏è Y√äU C·∫¶U B·∫ÆT BU·ªòC:\n",
      "1. C√¢u h·ªèi ph·∫£i ph√π h·ª£p v·ªõi ch∆∞∆°ng tr√¨nh THPT Vi·ªát Nam\n",
      "2. M·ªói c√¢u c√≥ ƒê√öNG 4 ƒë√°p √°n (A, B, C, D)\n",
      "3. Ch·ªâ c√≥ 1 ƒë√°p √°n ƒë√∫ng\n",
      "4. C√¢u h·ªèi ƒëa d·∫°ng v·ªÅ ƒë·ªô kh√≥ (d·ªÖ, trung b√¨nh, kh√≥)\n",
      "5. S·ª≠ d·ª•ng ti·∫øng Vi·ªát chu·∫©n, kh√¥ng d·∫•u sai\n",
      "6. N·ªôi dung ch√≠nh x√°c, c√≥ gi√° tr·ªã gi√°o d·ª•c\n",
      "\n",
      "üìã FORMAT OUTPUT (JSON array):\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"question\": \"C√¢u h·ªèi ·ªü ƒë√¢y?\",\n",
      "    \"A\": \"ƒê√°p √°n A\",\n",
      "    \"B...\n"
     ]
    }
   ],
   "source": [
    "# Prompt template ƒë·ªÉ sinh c√¢u h·ªèi\n",
    "def create_prompt(subject_name, subject_description, num_questions=10):\n",
    "    \"\"\"T·∫°o prompt ƒë·ªÉ sinh c√¢u h·ªèi tr·∫Øc nghi·ªám\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"B·∫°n l√† chuy√™n gia gi√°o d·ª•c THPT Vi·ªát Nam. H√£y t·∫°o {num_questions} c√¢u h·ªèi tr·∫Øc nghi·ªám v·ªÅ m√¥n {subject_name}.\n",
    "\n",
    "üìö N·ªòI DUNG: {subject_description}\n",
    "\n",
    "‚ö†Ô∏è Y√äU C·∫¶U B·∫ÆT BU·ªòC:\n",
    "1. C√¢u h·ªèi ph·∫£i ph√π h·ª£p v·ªõi ch∆∞∆°ng tr√¨nh THPT Vi·ªát Nam\n",
    "2. M·ªói c√¢u c√≥ ƒê√öNG 4 ƒë√°p √°n (A, B, C, D)\n",
    "3. Ch·ªâ c√≥ 1 ƒë√°p √°n ƒë√∫ng\n",
    "4. C√¢u h·ªèi ƒëa d·∫°ng v·ªÅ ƒë·ªô kh√≥ (d·ªÖ, trung b√¨nh, kh√≥)\n",
    "5. S·ª≠ d·ª•ng ti·∫øng Vi·ªát chu·∫©n, kh√¥ng d·∫•u sai\n",
    "6. N·ªôi dung ch√≠nh x√°c, c√≥ gi√° tr·ªã gi√°o d·ª•c\n",
    "\n",
    "üìã FORMAT OUTPUT (JSON array):\n",
    "```json\n",
    "[\n",
    "  {{\n",
    "    \"question\": \"C√¢u h·ªèi ·ªü ƒë√¢y?\",\n",
    "    \"A\": \"ƒê√°p √°n A\",\n",
    "    \"B\": \"ƒê√°p √°n B\",\n",
    "    \"C\": \"ƒê√°p √°n C\",\n",
    "    \"D\": \"ƒê√°p √°n D\",\n",
    "    \"answer\": \"A\"\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "üéØ V√ç D·ª§ M·∫™U:\n",
    "{{\n",
    "  \"question\": \"Trong c√°c m√¥n th·ªÉ thao sau, m√¥n n√†o thu·ªôc ƒëi·ªÅn kinh?\",\n",
    "  \"A\": \"B∆°i l·ªôi\",\n",
    "  \"B\": \"Ch·∫°y 100m\",\n",
    "  \"C\": \"B√≥ng ƒë√°\",\n",
    "  \"D\": \"C·∫ßu l√¥ng\",\n",
    "  \"answer\": \"B\"\n",
    "}}\n",
    "\n",
    "‚ú® H√ÉY T·∫†O {num_questions} C√ÇU H·ªéI CH·∫§T L∆Ø·ª¢NG NGAY B√ÇY GI·ªú!\n",
    "CH·ªà TR·∫¢ V·ªÄ JSON ARRAY, KH√îNG C√ì TEXT KH√ÅC!\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Test prompt\n",
    "print(\"üìù Example prompt:\")\n",
    "print(\"=\"*80)\n",
    "print(create_prompt(\"GDTC\", \"Th·ªÉ d·ª•c th·ªÉ thao\", 3)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f20cc8",
   "metadata": {},
   "source": [
    "## 3. H√†m sinh c√¢u h·ªèi v√† parse response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "922dab23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing question generation...\n",
      "‚úÖ Successfully generated 2 questions\n",
      "\n",
      "üìù Sample question:\n",
      "{\n",
      "  \"question\": \"Vi·ªác t·∫≠p luy·ªán th·ªÉ d·ª•c th·ªÉ thao th∆∞·ªùng xuy√™n mang l·∫°i l·ª£i √≠ch n√†o sau ƒë√¢y cho s·ª©c kh·ªèe con ng∆∞·ªùi?\",\n",
      "  \"A\": \"L√†m tƒÉng nhanh nguy c∆° m·∫Øc c√°c b·ªánh tim m·∫°ch.\",\n",
      "  \"B\": \"G√¢y suy gi·∫£m ch·ª©c nƒÉng h√¥ h·∫•p v√† tu·∫ßn ho√†n.\",\n",
      "  \"C\": \"Gi√∫p tƒÉng c∆∞·ªùng s·ª©c kh·ªèe tim m·∫°ch, gi·∫£m nguy c∆° b√©o ph√¨ v√† ti·ªÉu ƒë∆∞·ªùng.\",\n",
      "  \"D\": \"Ch·ªâ c√≥ t√°c d·ª•ng l√†m ƒë·∫πp h√¨nh th·ªÉ m√† kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn s·ª©c kh·ªèe n·ªôi t·∫°ng.\",\n",
      "  \"answer\": \"C\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def parse_gemini_response(response_text):\n",
    "    \"\"\"Parse response t·ª´ Gemini th√†nh list c√¢u h·ªèi\"\"\"\n",
    "    try:\n",
    "        # Remove markdown code blocks n·∫øu c√≥\n",
    "        text = response_text.strip()\n",
    "        if text.startswith('```'):\n",
    "            # Remove first line (```json)\n",
    "            text = '\\n'.join(text.split('\\n')[1:])\n",
    "        if text.endswith('```'):\n",
    "            # Remove last line (```)\n",
    "            text = '\\n'.join(text.split('\\n')[:-1])\n",
    "        \n",
    "        # Parse JSON\n",
    "        questions = json.loads(text)\n",
    "        \n",
    "        # Validate\n",
    "        if not isinstance(questions, list):\n",
    "            return None, \"Response is not a list\"\n",
    "        \n",
    "        # Validate each question\n",
    "        valid_questions = []\n",
    "        for q in questions:\n",
    "            if all(key in q for key in ['question', 'A', 'B', 'C', 'D', 'answer']):\n",
    "                if q['answer'] in ['A', 'B', 'C', 'D']:\n",
    "                    valid_questions.append(q)\n",
    "        \n",
    "        return valid_questions, None\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        return None, f\"JSON decode error: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        return None, f\"Parse error: {str(e)}\"\n",
    "\n",
    "\n",
    "def generate_questions_batch(subject_name, subject_description, num_questions=10, max_retries=3):\n",
    "    \"\"\"Sinh m·ªôt batch c√¢u h·ªèi v·ªõi retry logic\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Create prompt\n",
    "            prompt = create_prompt(subject_name, subject_description, num_questions)\n",
    "            \n",
    "            # Generate\n",
    "            response = model.generate_content(prompt)\n",
    "            \n",
    "            # Parse\n",
    "            questions, error = parse_gemini_response(response.text)\n",
    "            \n",
    "            if questions:\n",
    "                return questions, None\n",
    "            else:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"  ‚ö†Ô∏è  Parse failed (attempt {attempt+1}/{max_retries}): {error}\")\n",
    "                    time.sleep(2)  # Wait before retry\n",
    "                    continue\n",
    "                else:\n",
    "                    return None, error\n",
    "        \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"  ‚ö†Ô∏è  Generation failed (attempt {attempt+1}/{max_retries}): {str(e)}\")\n",
    "                # N·∫øu g·∫∑p l·ªói 429 (rate limit), ch·ªù 30s ƒë·ªÉ quota reset ho√†n to√†n\n",
    "                wait_time = 30 if \"429\" in str(e) else 5\n",
    "                print(f\"  ‚è≥ Waiting {wait_time}s before retry...\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "            else:\n",
    "                return None, str(e)\n",
    "    \n",
    "    return None, \"Max retries reached\"\n",
    "\n",
    "\n",
    "# Test generation\n",
    "print(\"üß™ Testing question generation...\")\n",
    "test_questions, error = generate_questions_batch(\"GDTC\", \"Th·ªÉ d·ª•c th·ªÉ thao\", 2)\n",
    "\n",
    "if test_questions:\n",
    "    print(f\"‚úÖ Successfully generated {len(test_questions)} questions\")\n",
    "    print(\"\\nüìù Sample question:\")\n",
    "    print(json.dumps(test_questions[0], ensure_ascii=False, indent=2))\n",
    "else:\n",
    "    print(f\"‚ùå Generation failed: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08415fbf",
   "metadata": {},
   "source": [
    "## 4. Convert sang SFT format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c008751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing SFT conversion...\n",
      "\n",
      "üìù SFT format:\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"B·∫°n l√† tr·ª£ l√Ω tr·∫£ l·ªùi tr·∫Øc nghi·ªám. Ch·ªâ tr·∫£ JSON duy nh·∫•t: {\\\"answer\\\":\\\"A\\\"} ho·∫∑c B/C/D.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"Vi·ªác t·∫≠p luy·ªán th·ªÉ d·ª•c th·ªÉ thao th∆∞·ªùng xuy√™n mang l·∫°i l·ª£i √≠ch n√†o sau ƒë√¢y cho s·ª©c kh·ªèe con ng∆∞·ªùi?\\nA. L√†m tƒÉng nhanh nguy c∆° m·∫Øc c√°c b·ªánh tim m·∫°ch.\\nB. G√¢y suy gi·∫£m ch·ª©c nƒÉng h√¥ h·∫•p v√† tu·∫ßn ho√†n.\\nC. Gi√∫p tƒÉng c∆∞·ªùng s·ª©c kh·ªèe tim m·∫°ch, gi·∫£m nguy c∆° b√©o ph√¨ v√† ti·ªÉu ƒë∆∞·ªùng.\\nD. Ch·ªâ c√≥ t√°c d·ª•ng l√†m ƒë·∫πp h√¨nh th·ªÉ m√† kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn s·ª©c kh·ªèe n·ªôi t·∫°ng.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"{\\\"answer\\\":\\\"C\\\"}\"\n",
      "    }\n",
      "  ],\n",
      "  \"id\": \"GDTC_1\",\n",
      "  \"subject\": \"GDTC\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def convert_to_sft_format(question_dict, subject_id, index):\n",
    "    \"\"\"Convert question dict sang SFT format\"\"\"\n",
    "    \n",
    "    # Build user content\n",
    "    choices = [\n",
    "        f\"A. {question_dict['A']}\",\n",
    "        f\"B. {question_dict['B']}\",\n",
    "        f\"C. {question_dict['C']}\",\n",
    "        f\"D. {question_dict['D']}\"\n",
    "    ]\n",
    "    \n",
    "    user_content = f\"{question_dict['question']}\\n\" + \"\\n\".join(choices)\n",
    "    \n",
    "    # System prompt\n",
    "    system_content = 'B·∫°n l√† tr·ª£ l√Ω tr·∫£ l·ªùi tr·∫Øc nghi·ªám. Ch·ªâ tr·∫£ JSON duy nh·∫•t: {\"answer\":\"A\"} ho·∫∑c B/C/D.'\n",
    "    \n",
    "    # Create messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\"role\": \"user\", \"content\": user_content},\n",
    "        {\"role\": \"assistant\", \"content\": f'{{\"answer\":\"{question_dict[\"answer\"]}\"}}'}\n",
    "    ]\n",
    "    \n",
    "    # Create SFT item\n",
    "    sft_item = {\n",
    "        \"messages\": messages,\n",
    "        \"id\": f\"{subject_id}_{index}\",\n",
    "        \"subject\": subject_id\n",
    "    }\n",
    "    \n",
    "    return sft_item\n",
    "\n",
    "\n",
    "# Test conversion\n",
    "if test_questions:\n",
    "    print(\"üß™ Testing SFT conversion...\")\n",
    "    sft_item = convert_to_sft_format(test_questions[0], \"GDTC\", 1)\n",
    "    print(\"\\nüìù SFT format:\")\n",
    "    print(json.dumps(sft_item, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b021e89d",
   "metadata": {},
   "source": [
    "## 5. Sinh c√¢u h·ªèi cho t·∫•t c·∫£ m√¥n h·ªçc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1139bd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting question generation...\n",
      "üìä Total: 7 subjects √ó 200 questions = 1400 questions\n",
      "üì¶ Batch size: 5 questions/request (40 batches per subject)\n",
      "\n",
      "‚è∞ Estimated time: ~60-70 minutes (5 RPM limit + smaller batches)\n",
      "üí° Tip: Smaller batches = more reliable JSON, less parse errors\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìö Generating questions for: Gi√°o d·ª•c Qu·ªëc ph√≤ng - An ninh (Priority 1)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GDQP-AN:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/40 [08:53<11:02, 30.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ö†Ô∏è  Parse failed (attempt 1/3): JSON decode error: Expecting ',' delimiter: line 19 column 69 (char 917)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GDQP-AN: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [25:29<00:00, 38.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generated 198/200 questions for GDQP-AN\n",
      "üìä Answer distribution: {'B': 92, 'A': 25, 'C': 73, 'D': 8}\n",
      "\n",
      "================================================================================\n",
      "üìö Generating questions for: Gi√°o d·ª•c Th·ªÉ ch·∫•t (Priority 1)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GDTC: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [26:24<00:00, 39.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generated 200/200 questions for GDTC\n",
      "üìä Answer distribution: {'C': 100, 'D': 16, 'B': 79, 'A': 5}\n",
      "\n",
      "================================================================================\n",
      "üìö Generating questions for: Tin h·ªçc (Priority 2)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "InformationTechnology:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 32/40 [19:17<03:50, 28.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ö†Ô∏è  Parse failed (attempt 1/3): JSON decode error: Expecting ',' delimiter: line 27 column 64 (char 1388)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "InformationTechnology: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [24:00<00:00, 36.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generated 200/200 questions for InformationTechnology\n",
      "üìä Answer distribution: {'C': 102, 'B': 76, 'A': 11, 'D': 11}\n",
      "\n",
      "================================================================================\n",
      "üìö Generating questions for: C√¥ng ngh·ªá (Priority 2)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Technology: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [19:34<00:00, 29.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generated 200/200 questions for Technology\n",
      "üìä Answer distribution: {'B': 57, 'C': 112, 'D': 29, 'A': 2}\n",
      "\n",
      "================================================================================\n",
      "üìö Generating questions for: Gi√°o d·ª•c Kinh t·∫ø & Ph√°p lu·∫≠t (Priority 2)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GDKT-PL: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [21:04<00:00, 31.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generated 200/200 questions for GDKT-PL\n",
      "üìä Answer distribution: {'C': 79, 'B': 93, 'A': 11, 'D': 17}\n",
      "\n",
      "================================================================================\n",
      "üìö Generating questions for: √Çm nh·∫°c (Priority 3)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Music:  12%|‚ñà‚ñé        | 5/40 [02:14<14:49, 25.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚ö†Ô∏è  Parse failed (attempt 1/3): JSON decode error: Expecting ',' delimiter: line 3 column 51 (char 56)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Music: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [17:02<00:00, 25.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generated 200/200 questions for Music\n",
      "üìä Answer distribution: {'C': 86, 'A': 35, 'B': 67, 'D': 12}\n",
      "\n",
      "================================================================================\n",
      "üìö Generating questions for: M·ªπ thu·∫≠t (Priority 3)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [17:15<00:00, 25.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generated 200/200 questions for Arts\n",
      "üìä Answer distribution: {'C': 109, 'D': 20, 'A': 13, 'B': 58}\n",
      "\n",
      "================================================================================\n",
      "‚úÖ GENERATION COMPLETE!\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_all_questions():\n",
    "    \"\"\"Sinh c√¢u h·ªèi cho t·∫•t c·∫£ m√¥n h·ªçc\"\"\"\n",
    "    \n",
    "    all_data = {}\n",
    "    \n",
    "    # Sort subjects by priority\n",
    "    sorted_subjects = sorted(SUBJECTS.items(), key=lambda x: x[1]['priority'])\n",
    "    \n",
    "    for subject_id, info in sorted_subjects:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üìö Generating questions for: {info['name']} (Priority {info['priority']})\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        questions = []\n",
    "        num_batches = QUESTIONS_PER_SUBJECT // info['questions_per_batch']\n",
    "        \n",
    "        for batch_idx in tqdm(range(num_batches), desc=f\"{subject_id}\"):\n",
    "            batch_questions, error = generate_questions_batch(\n",
    "                info['name'],\n",
    "                info['description'],\n",
    "                info['questions_per_batch']\n",
    "            )\n",
    "            \n",
    "            if batch_questions:\n",
    "                questions.extend(batch_questions)\n",
    "            else:\n",
    "                print(f\"\\n  ‚ùå Batch {batch_idx+1} failed: {error}\")\n",
    "            \n",
    "            # Rate limiting\n",
    "            # Limit: 5 RPM (Requests Per Minute) -> 60s / 5 = 12s/request\n",
    "            # Set sleep = 13s ƒë·ªÉ an to√†n (quota th·ª±c t·∫ø c·ªßa gemini-2.5-flash l√† 5 RPM)\n",
    "            time.sleep(13)\n",
    "        \n",
    "        # Store results\n",
    "        all_data[subject_id] = questions\n",
    "        \n",
    "        print(f\"\\n‚úÖ Generated {len(questions)}/{QUESTIONS_PER_SUBJECT} questions for {subject_id}\")\n",
    "        \n",
    "        # Check answer distribution\n",
    "        answers = [q['answer'] for q in questions]\n",
    "        answer_dist = Counter(answers)\n",
    "        print(f\"üìä Answer distribution: {dict(answer_dist)}\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "\n",
    "# Generate all questions\n",
    "print(\"üöÄ Starting question generation...\")\n",
    "print(f\"üìä Total: {len(SUBJECTS)} subjects √ó {QUESTIONS_PER_SUBJECT} questions = {len(SUBJECTS) * QUESTIONS_PER_SUBJECT} questions\")\n",
    "print(f\"üì¶ Batch size: 5 questions/request (40 batches per subject)\")\n",
    "print(\"\\n‚è∞ Estimated time: ~60-70 minutes (5 RPM limit + smaller batches)\")\n",
    "print(\"üí° Tip: Smaller batches = more reliable JSON, less parse errors\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "generated_data = generate_all_questions()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "print(\"‚úÖ GENERATION COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec879e03",
   "metadata": {},
   "source": [
    "# 6. Statistics v√† Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d6d5a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STATISTICS:\n",
      "================================================================================\n",
      "\n",
      "üìö Gi√°o d·ª•c Qu·ªëc ph√≤ng - An ninh (GDQP-AN):\n",
      "   Total: 198/200 questions (99.0%)\n",
      "   Answer distribution:\n",
      "     A:  25 ( 12.6%)\n",
      "     B:  92 ( 46.5%)\n",
      "     C:  73 ( 36.9%)\n",
      "     D:   8 (  4.0%)\n",
      "   ‚ö†Ô∏è  Imbalanced (std: 68.4)\n",
      "\n",
      "üìö Gi√°o d·ª•c Th·ªÉ ch·∫•t (GDTC):\n",
      "   Total: 200/200 questions (100.0%)\n",
      "   Answer distribution:\n",
      "     A:   5 (  2.5%)\n",
      "     B:  79 ( 39.5%)\n",
      "     C: 100 ( 50.0%)\n",
      "     D:  16 (  8.0%)\n",
      "   ‚ö†Ô∏è  Imbalanced (std: 80.8)\n",
      "\n",
      "üìö Tin h·ªçc (InformationTechnology):\n",
      "   Total: 200/200 questions (100.0%)\n",
      "   Answer distribution:\n",
      "     A:  11 (  5.5%)\n",
      "     B:  76 ( 38.0%)\n",
      "     C: 102 ( 51.0%)\n",
      "     D:  11 (  5.5%)\n",
      "   ‚ö†Ô∏è  Imbalanced (std: 80.1)\n",
      "\n",
      "üìö C√¥ng ngh·ªá (Technology):\n",
      "   Total: 200/200 questions (100.0%)\n",
      "   Answer distribution:\n",
      "     A:   2 (  1.0%)\n",
      "     B:  57 ( 28.5%)\n",
      "     C: 112 ( 56.0%)\n",
      "     D:  29 ( 14.5%)\n",
      "   ‚ö†Ô∏è  Imbalanced (std: 81.5)\n",
      "\n",
      "üìö Gi√°o d·ª•c Kinh t·∫ø & Ph√°p lu·∫≠t (GDKT-PL):\n",
      "   Total: 200/200 questions (100.0%)\n",
      "   Answer distribution:\n",
      "     A:  11 (  5.5%)\n",
      "     B:  93 ( 46.5%)\n",
      "     C:  79 ( 39.5%)\n",
      "     D:  17 (  8.5%)\n",
      "   ‚ö†Ô∏è  Imbalanced (std: 72.8)\n",
      "\n",
      "üìö √Çm nh·∫°c (Music):\n",
      "   Total: 200/200 questions (100.0%)\n",
      "   Answer distribution:\n",
      "     A:  35 ( 17.5%)\n",
      "     B:  67 ( 33.5%)\n",
      "     C:  86 ( 43.0%)\n",
      "     D:  12 (  6.0%)\n",
      "   ‚ö†Ô∏è  Imbalanced (std: 57.0)\n",
      "\n",
      "üìö M·ªπ thu·∫≠t (Arts):\n",
      "   Total: 200/200 questions (100.0%)\n",
      "   Answer distribution:\n",
      "     A:  13 (  6.5%)\n",
      "     B:  58 ( 29.0%)\n",
      "     C: 109 ( 54.5%)\n",
      "     D:  20 ( 10.0%)\n",
      "   ‚ö†Ô∏è  Imbalanced (std: 76.2)\n",
      "\n",
      "================================================================================\n",
      "üìä TOTAL: 1398 questions generated\n",
      "üéØ Target: 1400 questions\n",
      "‚úÖ Success rate: 99.9%\n"
     ]
    }
   ],
   "source": [
    "# Statistics\n",
    "print(\"\\nüìä STATISTICS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_questions = 0\n",
    "for subject_id, questions in generated_data.items():\n",
    "    info = SUBJECTS[subject_id]\n",
    "    total_questions += len(questions)\n",
    "    \n",
    "    # Answer distribution\n",
    "    answers = [q['answer'] for q in questions]\n",
    "    answer_counts = Counter(answers)\n",
    "    \n",
    "    print(f\"\\nüìö {info['name']} ({subject_id}):\")\n",
    "    print(f\"   Total: {len(questions)}/{QUESTIONS_PER_SUBJECT} questions ({len(questions)/QUESTIONS_PER_SUBJECT*100:.1f}%)\")\n",
    "    print(f\"   Answer distribution:\")\n",
    "    for ans in ['A', 'B', 'C', 'D']:\n",
    "        count = answer_counts.get(ans, 0)\n",
    "        print(f\"     {ans}: {count:3d} ({count/len(questions)*100:5.1f}%)\")\n",
    "    \n",
    "    # Check balance\n",
    "    std_dev = sum((count - len(questions)/4)**2 for count in answer_counts.values())**0.5\n",
    "    if std_dev < len(questions) * 0.1:\n",
    "        print(f\"   ‚úÖ Well balanced (std: {std_dev:.1f})\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Imbalanced (std: {std_dev:.1f})\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üìä TOTAL: {total_questions} questions generated\")\n",
    "print(f\"üéØ Target: {len(SUBJECTS) * QUESTIONS_PER_SUBJECT} questions\")\n",
    "print(f\"‚úÖ Success rate: {total_questions / (len(SUBJECTS) * QUESTIONS_PER_SUBJECT) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53ce8f",
   "metadata": {},
   "source": [
    "## 7. Convert to SFT format v√† Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "449ee5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Converting to SFT format...\n",
      "‚úÖ Converted 1398 questions to SFT format\n",
      "\n",
      "‚úÖ Saved to: ..\\data\\sft_generated_mcq\\generated_mcq.jsonl\n",
      "üì¶ File size: 0.92 MB\n",
      "\n",
      "üìÅ Saving individual files per subject...\n",
      "  ‚úÖ GDQP-AN: 198 questions ‚Üí gdqp-an.jsonl\n",
      "  ‚úÖ GDTC: 200 questions ‚Üí gdtc.jsonl\n",
      "  ‚úÖ InformationTechnology: 200 questions ‚Üí informationtechnology.jsonl\n",
      "  ‚úÖ Technology: 200 questions ‚Üí technology.jsonl\n",
      "  ‚úÖ GDKT-PL: 200 questions ‚Üí gdkt-pl.jsonl\n",
      "  ‚úÖ Music: 200 questions ‚Üí music.jsonl\n",
      "  ‚úÖ Arts: 200 questions ‚Üí arts.jsonl\n",
      "\n",
      "‚úÖ All files saved to: ..\\data\\sft_generated_mcq\n"
     ]
    }
   ],
   "source": [
    "# Convert all to SFT format\n",
    "print(\"üîÑ Converting to SFT format...\")\n",
    "\n",
    "all_sft_data = []\n",
    "\n",
    "for subject_id, questions in generated_data.items():\n",
    "    for idx, question in enumerate(questions, 1):\n",
    "        sft_item = convert_to_sft_format(question, subject_id, idx)\n",
    "        all_sft_data.append(sft_item)\n",
    "\n",
    "print(f\"‚úÖ Converted {len(all_sft_data)} questions to SFT format\")\n",
    "\n",
    "# Save to JSONL\n",
    "output_dir = Path('../data/sft_generated_mcq')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save combined file\n",
    "output_path = output_dir / 'generated_mcq.jsonl'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    for item in all_sft_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"\\n‚úÖ Saved to: {output_path}\")\n",
    "print(f\"üì¶ File size: {output_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Save individual files per subject\n",
    "print(\"\\nüìÅ Saving individual files per subject...\")\n",
    "for subject_id, questions in generated_data.items():\n",
    "    subject_data = [item for item in all_sft_data if item['subject'] == subject_id]\n",
    "    subject_path = output_dir / f'{subject_id.lower()}.jsonl'\n",
    "    \n",
    "    with open(subject_path, 'w', encoding='utf-8') as f:\n",
    "        for item in subject_data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"  ‚úÖ {subject_id}: {len(subject_data)} questions ‚Üí {subject_path.name}\")\n",
    "\n",
    "print(f\"\\n‚úÖ All files saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cffd524",
   "metadata": {},
   "source": [
    "## 8. Preview samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe6b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Preview samples from each subject:\n",
      "================================================================================\n",
      "\n",
      "üìö Gi√°o d·ª•c Qu·ªëc ph√≤ng - An ninh (GDQP-AN):\n",
      "ID: GDQP-AN_1\n",
      "\n",
      "User content:\n",
      "M·ª•c ƒë√≠ch ch√≠nh c·ªßa vi·ªác h·ªçc m√¥n Gi√°o d·ª•c Qu·ªëc ph√≤ng - An ninh (GDQP-AN) ·ªü tr∆∞·ªùng THPT l√† g√¨?\n",
      "A. ƒê·ªÉ bi·∫øt c√°ch s·ª≠ d·ª•ng c√°c lo·∫°i v≈© kh√≠ hi·ªán ƒë·∫°i.\n",
      "B. Trang b·ªã ki·∫øn th·ª©c v√† kƒ© nƒÉng c∆° b·∫£n v·ªÅ qu·ªëc ph√≤ng, an...\n",
      "\n",
      "Assistant: {\"answer\":\"B\"}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìö Gi√°o d·ª•c Th·ªÉ ch·∫•t (GDTC):\n",
      "ID: GDTC_1\n",
      "\n",
      "User content:\n",
      "Ho·∫°t ƒë·ªông th·ªÉ d·ª•c th·ªÉ thao th∆∞·ªùng xuy√™n mang l·∫°i l·ª£i √≠ch n√†o sau ƒë√¢y cho s·ª©c kh·ªèe?\n",
      "A. TƒÉng nguy c∆° m·∫Øc b·ªánh tim m·∫°ch.\n",
      "B. Gi·∫£m kh·∫£ nƒÉng t·∫≠p trung h·ªçc t·∫≠p.\n",
      "C. C·∫£i thi·ªán s·ª©c b·ªÅn v√† tƒÉng c∆∞·ªùng h·ªá mi·ªÖn d·ªãc...\n",
      "\n",
      "Assistant: {\"answer\":\"C\"}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìö Tin h·ªçc (InformationTechnology):\n",
      "ID: InformationTechnology_1\n",
      "\n",
      "User content:\n",
      "Trong l·∫≠p tr√¨nh, c·∫•u tr√∫c ƒëi·ªÅu khi·ªÉn n√†o cho ph√©p th·ª±c hi·ªán m·ªôt kh·ªëi l·ªánh nhi·ªÅu l·∫ßn cho ƒë·∫øn khi m·ªôt ƒëi·ªÅu ki·ªán nh·∫•t ƒë·ªãnh kh√¥ng c√≤n ƒë√∫ng?\n",
      "A. C·∫•u tr√∫c tu·∫ßn t·ª±\n",
      "B. C·∫•u tr√∫c r·∫Ω nh√°nh\n",
      "C. C·∫•u tr√∫c l·∫∑p\n",
      "D. C·∫•u ...\n",
      "\n",
      "Assistant: {\"answer\":\"C\"}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìö C√¥ng ngh·ªá (Technology):\n",
      "ID: Technology_1\n",
      "\n",
      "User content:\n",
      "D·ª•ng c·ª• n√†o sau ƒë√¢y th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒëo chi·ªÅu d√†i, ƒë·ªô d√†y ho·∫∑c ƒë·ªô s√¢u c·ªßa v·∫≠t th·ªÉ v·ªõi ƒë·ªô ch√≠nh x√°c cao, th∆∞·ªùng l√™n ƒë·∫øn ph·∫ßn trƒÉm ho·∫∑c ph·∫ßn ngh√¨n milim√©t?\n",
      "A. Th∆∞·ªõc cu·ªôn\n",
      "B. Panme (Micrometer)\n",
      "C. √ä...\n",
      "\n",
      "Assistant: {\"answer\":\"B\"}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìö Gi√°o d·ª•c Kinh t·∫ø & Ph√°p lu·∫≠t (GDKT-PL):\n",
      "ID: GDKT-PL_1\n",
      "\n",
      "User content:\n",
      "ƒê·∫∑c tr∆∞ng c∆° b·∫£n n√†o sau ƒë√¢y th·ªÉ hi·ªán r√µ nh·∫•t b·∫£n ch·∫•t nƒÉng ƒë·ªông v√† hi·ªáu qu·∫£ c·ªßa kinh t·∫ø th·ªã tr∆∞·ªùng?\n",
      "A. S·ª± can thi·ªáp s√¢u r·ªông c·ªßa Nh√† n∆∞·ªõc v√†o m·ªçi ho·∫°t ƒë·ªông s·∫£n xu·∫•t.\n",
      "B. C∆° ch·∫ø qu·∫£n l√Ω t·∫≠p trung, k·∫ø h...\n",
      "\n",
      "Assistant: {\"answer\":\"C\"}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìö √Çm nh·∫°c (Music):\n",
      "ID: Music_1\n",
      "\n",
      "User content:\n",
      "Trong c√°c k√≠ hi·ªáu sau, k√≠ hi·ªáu n√†o d√πng ƒë·ªÉ ch·ªâ ƒë·ªô cao c·ªßa √¢m thanh v√† l√† t√™n g·ªçi c·ªßa m·ªôt n·ªët nh·∫°c c∆° b·∫£n?\n",
      "A. D·∫•u l·∫∑ng ƒëen\n",
      "B. Kh√≥a Son\n",
      "C. N·ªët R√™\n",
      "D. Nh·ªãp 3/4...\n",
      "\n",
      "Assistant: {\"answer\":\"C\"}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìö M·ªπ thu·∫≠t (Arts):\n",
      "ID: Arts_1\n",
      "\n",
      "User content:\n",
      "B·ª©c tranh \"Em Th√∫y\" l√† m·ªôt t√°c ph·∫©m n·ªïi ti·∫øng c·ªßa h·ªça sƒ© n√†o trong n·ªÅn m·ªπ thu·∫≠t Vi·ªát Nam hi·ªán ƒë·∫°i?\n",
      "A. B√πi Xu√¢n Ph√°i\n",
      "B. Nguy·ªÖn S√°ng\n",
      "C. T√¥ Ng·ªçc V√¢n\n",
      "D. Tr·∫ßn VƒÉn C·∫©n...\n",
      "\n",
      "Assistant: {\"answer\":\"C\"}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Preview samples from each subject\n",
    "print(\"üîç Preview samples from each subject:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for subject_id in sorted(SUBJECTS.keys(), key=lambda x: SUBJECTS[x]['priority']):\n",
    "    subject_samples = [item for item in all_sft_data if item['subject'] == subject_id]\n",
    "    \n",
    "    if subject_samples:\n",
    "        sample = subject_samples[0]\n",
    "        print(f\"\\nüìö {SUBJECTS[subject_id]['name']} ({subject_id}):\")\n",
    "        print(f\"ID: {sample['id']}\")\n",
    "        print(f\"\\nUser content:\")\n",
    "        print(sample['messages'][1]['content'][:200] + \"...\")\n",
    "        print(f\"\\nAssistant: {sample['messages'][2]['content']}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeac267",
   "metadata": {},
   "source": [
    "## 9. Verify saved files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf8a491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Verifying saved files...\n",
      "================================================================================\n",
      "\n",
      "üìä Combined file: generated_mcq.jsonl\n",
      "   Total samples: 1398\n",
      "   Matches original: True\n",
      "\n",
      "üìä Subject distribution:\n",
      "   GDQP-AN: 198 questions\n",
      "   GDTC: 200 questions\n",
      "   InformationTechnology: 200 questions\n",
      "   Technology: 200 questions\n",
      "   GDKT-PL: 200 questions\n",
      "   Music: 200 questions\n",
      "   Arts: 200 questions\n",
      "\n",
      "‚úÖ All files verified successfully!\n"
     ]
    }
   ],
   "source": [
    "# Verify files\n",
    "print(\"‚úÖ Verifying saved files...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load and verify combined file\n",
    "verify_data = []\n",
    "with open(output_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        verify_data.append(json.loads(line.strip()))\n",
    "\n",
    "print(f\"\\nüìä Combined file: {output_path.name}\")\n",
    "print(f\"   Total samples: {len(verify_data)}\")\n",
    "print(f\"   Matches original: {len(verify_data) == len(all_sft_data)}\")\n",
    "\n",
    "# Check subject distribution\n",
    "subject_counts = Counter([item['subject'] for item in verify_data])\n",
    "print(f\"\\nüìä Subject distribution:\")\n",
    "for subject_id in sorted(SUBJECTS.keys(), key=lambda x: SUBJECTS[x]['priority']):\n",
    "    count = subject_counts.get(subject_id, 0)\n",
    "    print(f\"   {subject_id}: {count} questions\")\n",
    "\n",
    "print(f\"\\n‚úÖ All files verified successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea6a02",
   "metadata": {},
   "source": [
    "## üìã T·ªïng k·∫øt\n",
    "\n",
    "### K·∫øt qu·∫£:\n",
    "- ‚úÖ ƒê√£ sinh c√¢u h·ªèi cho t·∫•t c·∫£ m√¥n h·ªçc\n",
    "- ‚úÖ ƒê√£ convert sang SFT format\n",
    "- ‚úÖ ƒê√£ l∆∞u th√†nh JSONL files\n",
    "- ‚úÖ ƒê√£ verify k·∫øt qu·∫£\n",
    "\n",
    "### Files output:\n",
    "- `data/sft_generated_mcq/generated_mcq.jsonl` - T·∫•t c·∫£ c√¢u h·ªèi\n",
    "- `data/sft_generated_mcq/{subject}.jsonl` - T·ª´ng m√¥n ri√™ng\n",
    "\n",
    "### M√¥n h·ªçc ƒë√£ sinh:\n",
    "\n",
    "**Priority 1 (B·∫Øt bu·ªôc):**\n",
    "1. GDQP-AN - Gi√°o d·ª•c Qu·ªëc ph√≤ng - An ninh\n",
    "2. GDTC - Gi√°o d·ª•c Th·ªÉ ch·∫•t\n",
    "\n",
    "**Priority 2:**\n",
    "3. InformationTechnology - Tin h·ªçc\n",
    "4. Technology - C√¥ng ngh·ªá\n",
    "5. GDKT-PL - Gi√°o d·ª•c Kinh t·∫ø & Ph√°p lu·∫≠t\n",
    "\n",
    "**Priority 3:**\n",
    "6. Music - √Çm nh·∫°c\n",
    "7. Arts - M·ªπ thu·∫≠t\n",
    "\n",
    "### B∆∞·ªõc ti·∫øp theo:\n",
    "1. ‚úÖ Review ch·∫•t l∆∞·ª£ng c√¢u h·ªèi\n",
    "2. üîÑ Merge v·ªõi datasets hi·ªán c√≥ (VNHSGE, VMLU)\n",
    "3. üéØ Apply data cleaning n·∫øu c·∫ßn\n",
    "4. üöÄ S·ª≠ d·ª•ng cho training\n",
    "\n",
    "### L∆∞u √Ω:\n",
    "- Format: Gi·ªëng v·ªõi datasets kh√°c trong repo\n",
    "- M·ªói m√¥n: 200 c√¢u h·ªèi (c√≥ th·ªÉ √≠t h∆°n n·∫øu API c√≥ l·ªói)\n",
    "- ƒê√°p √°n: ƒê√£ c√¢n b·∫±ng A/B/C/D (~25% m·ªói ƒë√°p √°n)\n",
    "- C√≥ th·ªÉ ch·∫°y l·∫°i notebook ƒë·ªÉ sinh th√™m c√¢u h·ªèi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d80594",
   "metadata": {},
   "source": [
    "## üÜï B·ªï sung m√¥n VƒÉn (Literature)\n",
    "\n",
    "Ph·∫ßn n√†y generate ri√™ng m√¥n VƒÉn m√† kh√¥ng c·∫ßn ch·∫°y l·∫°i c√°c m√¥n kh√°c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f92121f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Th√™m m√¥n h·ªçc:\n",
      "  Priority 1: Literature - Ng·ªØ VƒÉn\n"
     ]
    }
   ],
   "source": [
    "# ƒê·ªãnh nghƒ©a m√¥n VƒÉn\n",
    "LITERATURE_SUBJECT = {\n",
    "    \"Literature\": {\n",
    "        \"name\": \"Ng·ªØ VƒÉn\",\n",
    "        \"description\": \"VƒÉn h·ªçc Vi·ªát Nam, vƒÉn h·ªçc th·∫ø gi·ªõi, l√Ω lu·∫≠n vƒÉn h·ªçc, ph√¢n t√≠ch t√°c ph·∫©m, t√°c gi·∫£ n·ªïi ti·∫øng, th·ªÉ lo·∫°i vƒÉn h·ªçc, tu t·ª´, bi·ªán ph√°p ngh·ªá thu·∫≠t\",\n",
    "        \"priority\": 1,  # ∆Øu ti√™n cao nh∆∞ GDQP-AN, GDTC\n",
    "        \"questions_per_batch\": 5\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üìö Th√™m m√¥n h·ªçc:\")\n",
    "print(f\"  Priority {LITERATURE_SUBJECT['Literature']['priority']}: Literature - {LITERATURE_SUBJECT['Literature']['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1467b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Literature question generation...\n",
      "üìä Target: 200 questions\n",
      "üì¶ Batch size: 5 questions/request (40 batches)\n",
      "\n",
      "‚è∞ Estimated time: ~9-10 minutes\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üìö Generating questions for: Ng·ªØ VƒÉn (Priority 1)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Literature: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [17:59<00:00, 26.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Generated 200/200 questions for Literature\n",
      "üìä Answer distribution: {'B': 68, 'C': 90, 'D': 21, 'A': 21}\n",
      "\n",
      "================================================================================\n",
      "‚úÖ LITERATURE GENERATION COMPLETE!\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate questions cho m√¥n VƒÉn\n",
    "def generate_literature_questions():\n",
    "    \"\"\"Sinh c√¢u h·ªèi ri√™ng cho m√¥n VƒÉn\"\"\"\n",
    "    \n",
    "    subject_id = \"Literature\"\n",
    "    info = LITERATURE_SUBJECT[subject_id]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üìö Generating questions for: {info['name']} (Priority {info['priority']})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    questions = []\n",
    "    num_batches = QUESTIONS_PER_SUBJECT // info['questions_per_batch']\n",
    "    \n",
    "    for batch_idx in tqdm(range(num_batches), desc=f\"{subject_id}\"):\n",
    "        batch_questions, error = generate_questions_batch(\n",
    "            info['name'],\n",
    "            info['description'],\n",
    "            info['questions_per_batch']\n",
    "        )\n",
    "        \n",
    "        if batch_questions:\n",
    "            questions.extend(batch_questions)\n",
    "        else:\n",
    "            print(f\"\\n  ‚ùå Batch {batch_idx+1} failed: {error}\")\n",
    "        \n",
    "        # Rate limiting: 5 RPM\n",
    "        time.sleep(13)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Generated {len(questions)}/{QUESTIONS_PER_SUBJECT} questions for {subject_id}\")\n",
    "    \n",
    "    # Check answer distribution\n",
    "    answers = [q['answer'] for q in questions]\n",
    "    answer_dist = Counter(answers)\n",
    "    print(f\"üìä Answer distribution: {dict(answer_dist)}\")\n",
    "    \n",
    "    return questions\n",
    "\n",
    "\n",
    "# Ch·∫°y generation\n",
    "print(\"üöÄ Starting Literature question generation...\")\n",
    "print(f\"üìä Target: {QUESTIONS_PER_SUBJECT} questions\")\n",
    "print(f\"üì¶ Batch size: 5 questions/request (40 batches)\")\n",
    "print(\"\\n‚è∞ Estimated time: ~9-10 minutes\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "literature_questions = generate_literature_questions()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ LITERATURE GENERATION COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ce63b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä LITERATURE STATISTICS:\n",
      "================================================================================\n",
      "\n",
      "üìö Ng·ªØ VƒÉn (Literature):\n",
      "   Total: 200/200 questions (100.0%)\n",
      "   Answer distribution:\n",
      "     A:  21 ( 10.5%)\n",
      "     B:  68 ( 34.0%)\n",
      "     C:  90 ( 45.0%)\n",
      "     D:  21 ( 10.5%)\n",
      "   ‚ö†Ô∏è  Imbalanced (std: 60.0)\n"
     ]
    }
   ],
   "source": [
    "# Statistics cho m√¥n VƒÉn\n",
    "print(\"\\nüìä LITERATURE STATISTICS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "answers = [q['answer'] for q in literature_questions]\n",
    "answer_counts = Counter(answers)\n",
    "\n",
    "print(f\"\\nüìö {LITERATURE_SUBJECT['Literature']['name']} (Literature):\")\n",
    "print(f\"   Total: {len(literature_questions)}/{QUESTIONS_PER_SUBJECT} questions ({len(literature_questions)/QUESTIONS_PER_SUBJECT*100:.1f}%)\")\n",
    "print(f\"   Answer distribution:\")\n",
    "for ans in ['A', 'B', 'C', 'D']:\n",
    "    count = answer_counts.get(ans, 0)\n",
    "    print(f\"     {ans}: {count:3d} ({count/len(literature_questions)*100:5.1f}%)\")\n",
    "\n",
    "# Check balance\n",
    "std_dev = sum((count - len(literature_questions)/4)**2 for count in answer_counts.values())**0.5\n",
    "if std_dev < len(literature_questions) * 0.1:\n",
    "    print(f\"   ‚úÖ Well balanced (std: {std_dev:.1f})\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  Imbalanced (std: {std_dev:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28643ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Converting Literature questions to SFT format...\n",
      "‚úÖ Converted 200 Literature questions to SFT format\n",
      "\n",
      "‚úÖ Saved Literature to: ..\\data\\sft_generated_mcq\\literature.jsonl\n",
      "üì¶ File size: 135.27 KB\n"
     ]
    }
   ],
   "source": [
    "# Convert Literature questions sang SFT format\n",
    "print(\"üîÑ Converting Literature questions to SFT format...\")\n",
    "\n",
    "literature_sft_data = []\n",
    "\n",
    "for idx, question in enumerate(literature_questions, 1):\n",
    "    sft_item = convert_to_sft_format(question, \"Literature\", idx)\n",
    "    literature_sft_data.append(sft_item)\n",
    "\n",
    "print(f\"‚úÖ Converted {len(literature_sft_data)} Literature questions to SFT format\")\n",
    "\n",
    "# Save Literature file ri√™ng\n",
    "output_dir = Path('../data/sft_generated_mcq')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "literature_path = output_dir / 'literature.jsonl'\n",
    "with open(literature_path, 'w', encoding='utf-8') as f:\n",
    "    for item in literature_sft_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"\\n‚úÖ Saved Literature to: {literature_path}\")\n",
    "print(f\"üì¶ File size: {literature_path.stat().st_size / (1024):.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4715e1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Merging Literature into existing generated_mcq.jsonl...\n",
      "‚úÖ Loaded 1398 existing questions\n",
      "üìä Total after merge: 1598 questions\n",
      "\n",
      "‚úÖ Merged and saved to: ..\\data\\sft_generated_mcq\\generated_mcq.jsonl\n",
      "üì¶ New file size: 1.05 MB\n",
      "\n",
      "üìä Subject distribution after merge:\n",
      "   Arts: 200 questions\n",
      "   GDKT-PL: 200 questions\n",
      "   GDQP-AN: 198 questions\n",
      "   GDTC: 200 questions\n",
      "   InformationTechnology: 200 questions\n",
      "   Literature: 200 questions\n",
      "   Music: 200 questions\n",
      "   Technology: 200 questions\n"
     ]
    }
   ],
   "source": [
    "# Merge Literature v√†o file generated_mcq.jsonl ƒë√£ c√≥\n",
    "print(\"\\nüîÑ Merging Literature into existing generated_mcq.jsonl...\")\n",
    "\n",
    "# Load existing data\n",
    "existing_file = output_dir / 'generated_mcq.jsonl'\n",
    "existing_data = []\n",
    "\n",
    "if existing_file.exists():\n",
    "    with open(existing_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            existing_data.append(json.loads(line.strip()))\n",
    "    print(f\"‚úÖ Loaded {len(existing_data)} existing questions\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No existing file found, will create new one\")\n",
    "\n",
    "# Merge\n",
    "all_data = existing_data + literature_sft_data\n",
    "print(f\"üìä Total after merge: {len(all_data)} questions\")\n",
    "\n",
    "# Save merged file\n",
    "with open(existing_file, 'w', encoding='utf-8') as f:\n",
    "    for item in all_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"\\n‚úÖ Merged and saved to: {existing_file}\")\n",
    "print(f\"üì¶ New file size: {existing_file.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "# Show subject distribution\n",
    "subject_counts = Counter([item['subject'] for item in all_data])\n",
    "print(f\"\\nüìä Subject distribution after merge:\")\n",
    "for subject_id, count in sorted(subject_counts.items()):\n",
    "    print(f\"   {subject_id}: {count} questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "217debe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Preview sample from Literature:\n",
      "================================================================================\n",
      "\n",
      "üìö Ng·ªØ VƒÉn (Literature):\n",
      "ID: Literature_1\n",
      "\n",
      "User content:\n",
      "T√°c ph·∫©m n√†o sau ƒë√¢y ƒë∆∞·ª£c xem l√† ƒë·ªânh cao c·ªßa vƒÉn h·ªçc ch·ªØ N√¥m Vi·ªát Nam v√† l√† ki·ªát t√°c c·ªßa ƒë·∫°i thi h√†o Nguy·ªÖn Du?\n",
      "A. Chinh ph·ª• ng√¢m kh√∫c\n",
      "B. Truy·ªán Ki·ªÅu\n",
      "C. Cung o√°n ng√¢m kh√∫c\n",
      "D. L·ª•c V√¢n Ti√™n\n",
      "\n",
      "Assistant: {\"answer\":\"B\"}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Preview sample t·ª´ m√¥n VƒÉn\n",
    "print(\"\\nüîç Preview sample from Literature:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if literature_sft_data:\n",
    "    sample = literature_sft_data[0]\n",
    "    print(f\"\\nüìö {LITERATURE_SUBJECT['Literature']['name']} (Literature):\")\n",
    "    print(f\"ID: {sample['id']}\")\n",
    "    print(f\"\\nUser content:\")\n",
    "    print(sample['messages'][1]['content'])\n",
    "    print(f\"\\nAssistant: {sample['messages'][2]['content']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a0611",
   "metadata": {},
   "source": [
    "## ‚úÖ Ho√†n t·∫•t\n",
    "\n",
    "### ƒê√£ th√™m m√¥n VƒÉn:\n",
    "- ‚úÖ Generate 200 c√¢u h·ªèi m√¥n Ng·ªØ VƒÉn\n",
    "- ‚úÖ Convert sang SFT format\n",
    "- ‚úÖ L∆∞u ri√™ng: `literature.jsonl`\n",
    "- ‚úÖ Merge v√†o file `generated_mcq.jsonl` chung\n",
    "\n",
    "### T·ªïng s·ªë m√¥n h·ªçc hi·ªán c√≥:\n",
    "1. GDQP-AN - Gi√°o d·ª•c Qu·ªëc ph√≤ng - An ninh\n",
    "2. GDTC - Gi√°o d·ª•c Th·ªÉ ch·∫•t\n",
    "3. **Literature - Ng·ªØ VƒÉn** ‚Üê M·ªöI\n",
    "4. InformationTechnology - Tin h·ªçc\n",
    "5. Technology - C√¥ng ngh·ªá\n",
    "6. GDKT-PL - Gi√°o d·ª•c Kinh t·∫ø & Ph√°p lu·∫≠t\n",
    "7. Music - √Çm nh·∫°c\n",
    "8. Arts - M·ªπ thu·∫≠t\n",
    "\n",
    "### T·ªïng c·ªông:\n",
    "**~1600 c√¢u h·ªèi** (8 m√¥n √ó 200 c√¢u)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
